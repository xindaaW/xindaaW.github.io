---
permalink: /
title: "Welcome to Xinda Wang's Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I'm Xinda Wang, a Master's student at Peking University. I'm passionate about Large Language Models, particularly focusing on post-training and continual pre-training techniques.

## Research Interests

- **Large Language Model Post-training**: Exploring advanced techniques for fine-tuning and optimizing pre-trained language models
- **Continual Pre-training**: Investigating methods for efficiently updating language models with new knowledge while preserving existing capabilities
- **Natural Language Processing**: Working on various NLP tasks and applications

## About Me

I am currently pursuing my Master's degree at Peking University, where I'm deeply engaged in cutting-edge research in artificial intelligence and natural language processing. My work focuses on advancing the capabilities of large language models through innovative training methodologies.

## Current Work

My research primarily centers around:
- Developing efficient post-training techniques for large language models
- Exploring continual pre-training strategies that enable models to acquire new knowledge while maintaining their existing capabilities
- Investigating the theoretical foundations and practical applications of advanced NLP systems

## Contact

Feel free to reach out to me for research collaborations or academic discussions. You can find my contact information in the sidebar.
